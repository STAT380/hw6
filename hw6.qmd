---
title: "Homework 6"
author: "[Diana Batista Capellan]{style='background-color: yellow;'}"
toc: true
title-block-banner: true
title-block-style: default
execute: 
  freeze: true
  cache: true
# format:
  #html: # comment this line to get pdf
  pdf: 
    fig-width: 7
    fig-height: 7
---


::: {.callout-important style="font-size: 0.8em;"}

Please read the instructions carefully before submitting your assignment.

1. This assignment requires you to only upload a `PDF` file on Canvas
1. Don't collapse any code cells before submitting. 
1. Remember to make sure all your code output is rendered properly before uploading your submission.

⚠️ Please add your name to the author information in the frontmatter before submitting your assignment ⚠️
:::


In this assignment, we will perform various tasks involving principal component analysis (PCA), principal component regression, and dimensionality reduction.

We will need the following packages:


```{R, message=FALSE, warning=FALSE, results='hide'}
packages <- c(
  "tibble",
  "dplyr", 
  "readr", 
  "tidyr", 
  "purrr", 
  "broom",
  "magrittr",
  "corrplot",
  "car"
)
#renv::install(packages)
sapply(packages, require, character.only=T)
```

<br><br><br><br>
---

## Question 1
::: {.callout-tip}
## 70 points
Principal component anlaysis and variable selection
:::

###### 1.1 (5 points)


The `data` folder contains a `spending.csv` dataset which is an illustrative sample of monthly spending data for a group of $5000$ people across a variety of categories. The response variable, `income`, is their monthly income, and objective is to predict the `income` for a an individual based on their spending patterns.

Read the data file as a tibble in R. Preprocess the data such that:

1. the variables are of the right data type, e.g., categorical variables are encoded as factors
2. all column names to lower case for consistency
3. Any observations with missing values are dropped

```{R}
path <- "data/spending.csv"

df <- read_csv(path) %>%
  mutate(across(everything(), tolower)) %>%
  drop_na() %>%
  mutate_all(as.double)# Insert your code here

head(df)
```

---

###### 1.2 (5 points)

Visualize the correlation between the variables using the `corrplot()` function. What do you observe? What does this mean for the model?

```{R}
correlation_matrix <- cor(df)
my_colors <- colorRampPalette(c("lightblue", "violet", "lightgreen"))(100)
corrplot(correlation_matrix, order = "original", tl.col = "black", col = my_colors) # Insert your code here
```
**I observe that each square represents a correlation and the size and color of each square indicate the strength and direction of the correlation. This means that high correlations between predictors may lead to multicollinearity issues, which can affect the stability and interpretability of the model coefficients.**
---

###### 1.3 (5 points)

Run a linear regression model to predict the `income` variable using the remaining predictors. Interpret the coefficients and summarize your results. 

```{R}
model <- lm(income ~ ., data = df)
summary(model) # Insert your code here
```

---

###### 1.3 (5 points)

Diagnose the model using the `vif()` function. What do you observe? What does this mean for the model?

```{R}
vif(model) # Insert your code here
```
**The VIF values indicate the extent of multicollinearity in the model. Generally, a VIF greater than 10 is considered problematic and suggests high multicollinearity.**
---

###### 1.4 (5 points)

Perform PCA using the `princomp` function in R. Print the summary of the PCA object.

```{R}
pca <- princomp(df) # Insert your code here
summary(pca) # Insert your code here
```

---

###### 1.5 (5 points)

Make a screeplot of the proportion of variance explained by each principal component. How many principal components would you choose to keep? Why?

```{R}
plot(pca, type = "lines", main = "Screeplot of PCA")

xlabel <- "Principal Component"
ylabel <- "Variance Explained"
title <- "Screeplot of PCA"
abline(h = 1, col = "red", lty = 2)  #reference line variance explained = 1
title(main = title, xlab = xlabel, ylab = ylabel) # Insert your code here
```
**I would choose to keep the components above Comp. 4 becasue they capture the majority of the variance in the data.**

###### 1.6 (5 points)

By setting any factor loadings below $0.2$ to $0$, summarize the factor loadings for the principal components that you chose to keep. 

```{R}
clean_loadings <- pca$loadings[, 1:4]
clean_loadings[clean_loadings < 0.2] <- 0 
clean_loadings# Insert your code here
```


Visualize the factor loadings. 

```{R}
my_colors <- c("lightblue", "violet", "lightgreen")

# Create a heatmap of factor loadings with custom colors
heatmap(clean_loadings, 
        Rowv = NULL, Colv = NULL, 
        col = my_colors, 
        scale = "none", 
        main = "Factor Loadings Heatmap",
        xlab = "Principal Components", 
        ylab = "Variables")
```

---

###### 1.7 (15 points)

Based on the factor loadings, what do you think the principal components represent? 

Provide an interpreation for each principal component you chose to keep.

**High loadings (positive or negative) indicate strong associations between variables and principal components. For example theres's high spending habits on video games, and streaming services and it is shown by the high loadings for those components.**
---

###### 1.8 (10 points)

Create a new data frame with the original response variable `income` and the principal components you chose to keep. Call this data frame `df_pca`.

```{R}
pca_scores <- predict(pca)
df_pca <- data.frame(income = df$income, pca_scores[, 1:4])  
head(df_pca) # Insert your code here
```

Fit a regression model to predict the `income` variable using the principal components you chose to keep. Interpret the coefficients and summarize your results. 

```{R}
model_pca <- lm(income ~ ., data = df_pca)
summary(model_pca) # Insert your code here
```

Compare the results of the regression model in 1.3 and 1.9. What do you observe? What does this mean for the model?

```{R}
summary(model)
summary(model_pca)# Insert your code here

```
**In the linear regression model using the original predictors, the coefficients represent the change in income associated with a one-unit change in each predictor variable, while holding all other predictors constant. In this model the interpretation of coefficients in terms of the original variables may be more straightforward in the model using original predictors and represent the direct effects of individual predictors.** 

**In the linear regression model using principal components, the coefficients represent the change in income associated with a one-unit change in each principal component, while holding all other principal components constant. This model also achieves a perfect fit (R-squared = 1), indicating that all the variance in income is explained by the principal components. This is expected since the number of principal components used equals the number of observations.**

---

###### 1.10 (10 points)

Based on your interpretation of the principal components from Question 1.7, provide an interpretation of the regression model in Question 1.9.

**The regression model in Question 1.9 captures the relationship between income and spending patterns represented by principal components, where each coefficient represents the change in income associated with a one-unit change in that principal component while holding others constant. Principal components with high loadings on luxury items, entertainment, and electronics indicate stronger associations with higher income, while those with high loadings on necessities or transportation-related items suggest associations with lower income.**

---


:::{.hidden unless-format="pdf"}
\pagebreak
:::

<br><br><br><br>
<br><br><br><br>
---



::: {.callout-note collapse="true"}
## Session Information

Print your `R` session information using the following command

```{R}
sessionInfo()
```
:::